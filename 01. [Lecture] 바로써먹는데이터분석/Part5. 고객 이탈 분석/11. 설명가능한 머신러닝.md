**설명 가능성/ 해석 가능성(Explainability/interpretability)**

#### 설명 가능성이 중요한 경우
1. 신뢰성 - 예측 결과 뿐만 아니라 예측의 이유도 알고 싶어한다.
2. 디버깅 - 모델 설명을 통해서 모델이 잘못된 이유로 예측을 수행하는지 검사

#### 설명 가능성이 필요 없는 경우
1. 모델의 영향력이 크지 않을 때 - 예측이 실패해도 위험성이 크지 않을 때 (ex. 영화 추천)
2. 모델이 충분히 검증되었을 때 - (ex. OCR 모델)
3. 조작 가능성을 막기 위해서 - (ex. 구글 검색)

#### 모델 설명 기법의 종류
* 본질적(Intrinsic)
    * 모델 자체가 복잡성이 낮아 설명 가능한 경우
    * 의사 결정 나무(decision tree), 선형 회귀(linear regression)
* 사후적(post hoc)
    *특정한 분석 기법을 도입하여 모델을 설명하는 경우
* 모델 종속적(model-specific)
    * 특정 모델에 적용할 수 있는 기법
* 모델 비종속적(model-agnostic)
    * 모델에 상관없이 적용 가능한 기법
* 전체적(global)
    * 전체 모델을 설명하는 기법
* 지역적(local)
    * 개별적인 예측 결과를 설명하는 기법

#### 모델 설명 기법의 결과물
* 학습된 가중치
    * 본질적으로 해석 가능한 모델의 경우 가중치를 통해 해석 가능
* 특성 요약 통계
    * 특성 중요도 등 각각의 특성에 대한 통계치 구하기
* 특성 요약 시각화
    * 특성에 대한 통계치 시각화
* 데이터 포인트
    * 몇 개의 데이터로 모델을 설명하는 기법
    * 프로토타입 예시 또는 모델이 틀리는 데이터를 통해 모델 설명
* 해석 가능한 모델
    * 복잡한 모델을 해석 가능한 단순한 모델로 근사하여 해석

#### LIME: Local Interpretable Model-Agnostic Explanations
* 모델 비종속적(model-agnostic)
* 지역적(local)
* 텍스트 분류라면, 어떤 텍스트를 위주로 예측했는지 설명
* 이미지 분류라면, 이미지의 어떤 부분을 보고 나온 것인지 파악 가능