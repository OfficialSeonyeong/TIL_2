# Part 3 리뷰 텍스트 분석

#### 01. 자연어 처리가 필요한 이유
* Structured data : 테이블, 데이터베이스, 컴퓨터로 처리 쉬움
* Unstructured data : 텍스트, 이미지, 영상, 컴퓨터로 처리 어려움
* 자연어(Natural Language) : 영어, 한국어와 같이 사람들이 일상적으로 쓰는 언어
* 자연어 처리(Natural Language Processing) : 인간 언어를 컴퓨터가 이해할 수 있도록 만드는 것
* 유저 보이스를 파악하고 분석하는 것이 비즈니스에서 중요해짐

#### 02. 텍스트 전처리
* 텍스트 전처리(Text Preprocessing) : 텍스트를 컴퓨터가 처리할 수 있게 만들어주는 다양한 과정
* 텍스트 정규화 (Text Normalization) : 의미가 같은 텍스트를 같은 형태로 바꿔주는 것
* 오타 정규화, 축약어 정규화, 대/소문자 정규화, URL과 문장부호 등 제거
* 불용어 제거 (Removing stopwords) : 내용적 의미를 갖지 않으면서 문법적으로 쓰이는 단어
* 어간 추출 (stemming) : 단어를 원형으로 바꿔주는 것, 주로 기계적으로 이루어짐 (running, runs -> run)
* 표제어 추출 (lemmatization) : 어간 추출과 비슷하지만 좀 더 정교하게 이루어짐(better, best -> good)

##### 텍스트 토큰화
* 토큰 (Token) : 컴퓨터가 텍스트를 처리하는 단위 (단어, 어간(stem)/표제어(lemma), 서브워드(subword))
* 토큰화 (Tokenization) : 텍스트를 토큰 단위로 쪼개는 것
* 띄어쓰기 기반 토큰
* 형태소 기반 토큰
* 서브워드(subword) 기반 토큰 : 통계적으로 구한 토큰 단위 사용
* One-hot encoding : 텍스트를 숫자형 데이터로 바꾸기

##### 텍스트 관련 파이썬 라이브러리
* NLTK 
* spaCy
* KoNLPy
* Huggingface Transformers

## 실전프로젝트 5)
### 토픽 모델링으로 리뷰 한눈에 보기

#### 01. Project Overview
* 토픽(Topic) : 텍스트에서 다루는 주된 대상
* 워드 클라우드(Word Cloud)
* TF-IDF
* 토픽 모델링 (Topic Modeling)
* LDA (Latent Dirichlet Allocation)

#### 02. 워드클라우드로 키워드 한눈에 보기
* 단어가 텍스트에 나오는 빈도가 높으면 단어의 크기가 큰 시각화
* 직관적, 쉽고 빠르다.
* 정확한 통계량을 알기 어렵다, 단어의 시각적인 표현과 중요도가 비례 X (단어 길이, 배치 등)
* 통계적인 결론을 내는 도구가 아닌 데이터에서 인사이트를 얻는 용도로 사용해야

#### 03. TF-IDF 이론
* 문서 내 단어의 중요도를 재는 측정 방법
* 중요도 측정 기준
* 단어가 문서 내에서 자주 등장할수록 중요하다. (TF)
* 하지만 stopwords나 일반적인 단어들도 자주 등장!
* 단어가 다른 문서에서도 자주 등장할수록 덜 중요하다. (IDF) => TF-IDF의 핵심 아이디어
* Term Frequency - Inverse Document Frequency

#### 04. TF-IDF로 의미없는 키워드 제거
실습 과정
1. spaCy를 이용해 텍스트 전처리
2. gensim을 이용해 bigram, trigram을 한 단어로 묶는다. (Phrase Modeling)
3. 자주 나오는 단어만 대상으로 분석 대상 단어 선정
4. 각 브랜드의 리뷰들의 tf-idf 점수들을 구해서 평균 구한다.
5. tf-idf 점수를 이용해 워드 클라우드를 그린다.

#### 05. 토픽 모델링 이론
* 문서들을 주제(topic)에 따라 묶는 기법

##### 전통적으로 문서를 표현하는 방법
1. 단어(또는 구문)의 묶음 Bag of words
2. 단어들의 등장 횟수를 벡터로 Count Vectorization
문제점 -> 문서 벡터가 너무 크다, 단어들 사이의 연관관계가 없다.

##### LDA
* 주제(topic)이라는 세번째 레이어를 추가
* 문서는 주제의 합, 주제는 단어들의 합
* Latent Dirichlet Allocation : 숨겨져 있는 Dirichlet 분포 할당
